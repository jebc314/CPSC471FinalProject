{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/Hryniewska/EnsembleXAI/blob/main/notebooks/Imagenet_tests_and_results.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import urllib.request\n",
    "import json\n",
    "from captum.attr import IntegratedGradients, Saliency, GradientShap, GuidedBackprop, Deconvolution, InputXGradient, Lime, Occlusion, ShapleyValueSampling, FeatureAblation, KernelShap, NoiseTunnel\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"C:\\\\Users\\\\jebcu\\\\Desktop\\\\CPSC471_Project\\\\input\"\n",
    "images_dir = input_dir + \"\\\\images\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\") as url:\n",
    "    imagenet_classes_dict = json.load(url)\n",
    "with urllib.request.urlopen(\"https://raw.githubusercontent.com/LUSSeg/ImageNet-S/main/data/categories/ImageNetS_categories_im50.txt\") as url:\n",
    "    imagenetS50_ids_dict = {str(x).replace(\"b'\", \"\").replace(\"\\\\n'\", \"\").replace(\"'\",\"\"):i+1 for i, x in enumerate(url)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_list(image_paths):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        for image_name in os.listdir(image_path):\n",
    "            image = Image.open(image_path + image_name)\n",
    "            if image.mode == 'L':\n",
    "                image = image.convert(mode='RGB')\n",
    "            images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_original = images_list([images_dir + classid + \"\\\\\" for classid in imagenetS50_ids_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do predictions with ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.eval()\n",
    "resnet_transform = ResNet18_Weights.DEFAULT.transforms()\n",
    "pipeline = lambda images: torch.stack([resnet_transform(image) for image in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_data = pipeline(all_images_original)\n",
    "outputs = model(proper_data)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "probs = torch.nn.functional.softmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(proper_data, \"ImageNet/proper_data.pt\")\n",
    "torch.save(preds, \"ImageNet/preds.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pred = preds[2].unsqueeze(dim=0)\n",
    "single_data = proper_data[2].unsqueeze(dim=0)\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "attributions_ig = integrated_gradients.attribute(single_data, target=single_pred, n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = resnet_transform(all_images_original[2])\n",
    "\n",
    "_ = viz.visualize_image_attr(\n",
    "    attributions_ig.permute(0, 2, 3, 1).tolist()[0],\n",
    "    transformed_img.permute(1, 2, 0).tolist(),\n",
    "    method=\"blended_heat_map\",\n",
    "    sign=\"all\",\n",
    "    show_colorbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_pred = preds[0:2]\n",
    "multiple_data = proper_data[0:2]\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "attributions_ig = integrated_gradients.attribute(multiple_data, target=multiple_pred, n_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions_ig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = resnet_transform(all_images_original[0])\n",
    "\n",
    "_ = viz.visualize_image_attr(\n",
    "    attributions_ig.permute(0, 2, 3, 1).tolist()[0],\n",
    "    transformed_img.permute(1, 2, 0).tolist(),\n",
    "    method=\"blended_heat_map\",\n",
    "    sign=\"all\",\n",
    "    show_colorbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = resnet_transform(all_images_original[1])\n",
    "\n",
    "_ = viz.visualize_image_attr(\n",
    "    attributions_ig.permute(0, 2, 3, 1).tolist()[1],\n",
    "    transformed_img.permute(1, 2, 0).tolist(),\n",
    "    method=\"blended_heat_map\",\n",
    "    sign=\"all\",\n",
    "    show_colorbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create superpixels\n",
    "Reference: https://www.kaggle.com/code/sukanyabag/lime-model-explainability-testing-pytorch and https://github.com/marcotcr/lime/blob/master/lime/lime_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import quickshift\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_masks = [quickshift(image, kernel_size=4, max_dist=200, ratio=0.2, channel_axis=0) for image in proper_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_masks = [torch.tensor(m) for m in proper_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proper_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proper_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_masks = torch.stack(proper_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proper_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(proper_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(proper_masks, \"ImageNet/proper_masks.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above code took 2 minutes 39.4 seconds. ~3 second per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributions (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensors\n",
    "proper_data = torch.load(\"ImageNet/proper_data.pt\").cuda()\n",
    "preds = torch.load(\"ImageNet/preds.pt\").cuda()\n",
    "proper_masks = torch.load(\"ImageNet/proper_masks.pt\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributions(explainer, num_batches = 50):\n",
    "    attributions = None\n",
    "    for i in range(num_batches):\n",
    "        batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "        if attributions is None:\n",
    "            attributions = explainer.attribute(proper_data[batch_slice], target=preds[batch_slice])\n",
    "        else:\n",
    "            temp = explainer.attribute(proper_data[batch_slice], target=preds[batch_slice])\n",
    "            attributions = torch.cat((attributions, temp), dim = 0)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cuda = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(model_cuda)\n",
    "attributions_ig = get_attributions(integrated_gradients)\n",
    "torch.save(attributions_ig, \"ImageNet/attributions_ig.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = Saliency(model_cuda)\n",
    "attributions_s = get_attributions(saliency)\n",
    "torch.save(attributions_s, \"ImageNet/attributions_s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_shap = GradientShap(model_cuda)\n",
    "attributions_gs = None\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "    if attributions_gs is None:\n",
    "        attributions_gs = gradient_shap.attribute(proper_data[batch_slice].cuda(), torch.zeros_like(proper_data[0:1]), target=preds[batch_slice].cuda())\n",
    "    else:\n",
    "        temp = gradient_shap.attribute(proper_data[batch_slice].cuda(), torch.zeros_like(proper_data[0:1]), target=preds[batch_slice].cuda())\n",
    "        attributions_gs = torch.cat((attributions_gs, temp), dim = 0)\n",
    "\n",
    "torch.save(attributions_gs, \"ImageNet/attributions_gs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_backprop = GuidedBackprop(model_cuda)\n",
    "attributions_gb = get_attributions(guided_backprop)\n",
    "torch.save(attributions_gb, \"ImageNet/attributions_gb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconvolution = Deconvolution(model_cuda)\n",
    "attributions_d = get_attributions(deconvolution)\n",
    "torch.save(attributions_d, \"ImageNet/attributions_d.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_gradient = InputXGradient(model_cuda)\n",
    "attributions_ixg = get_attributions(input_x_gradient)\n",
    "torch.save(attributions_ixg, \"ImageNet/attributions_ixg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need feature mask\n",
    "lime = Lime(model_cuda)\n",
    "attributions_l = None\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "    if attributions_l is None:\n",
    "        attributions_l = lime.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "    else:\n",
    "        temp = lime.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "        attributions_l = torch.cat((attributions_l, temp), dim = 0)\n",
    "\n",
    "torch.save(attributions_l, \"ImageNet/attributions_l.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above took 36.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occulsion = Occlusion(model_cuda)\n",
    "attributions_o = None\n",
    "\n",
    "# Using sliding window size (3, 15, 15) and strides = (3, 8, 8) as used in EnsembleXAI\n",
    "for i in range(num_batches):\n",
    "    batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "    if attributions_o is None:\n",
    "        attributions_o = occulsion.attribute(proper_data[batch_slice].cuda(), (3, 15, 15), target=preds[batch_slice].cuda(), strides = (3, 8, 8))\n",
    "    else:\n",
    "        temp = occulsion.attribute(proper_data[batch_slice].cuda(), (3, 15, 15), target=preds[batch_slice].cuda(), strides = (3, 8, 8))\n",
    "        attributions_o = torch.cat((attributions_o, temp), dim = 0)\n",
    "\n",
    "torch.save(attributions_o, \"ImageNet/attributions_o.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above took 3 minutes and 31.2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need feature mask\n",
    "shapley_value_sampling = ShapleyValueSampling(model_cuda)\n",
    "attributions_svs = None\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "    if attributions_svs is None:\n",
    "        attributions_svs = shapley_value_sampling.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "    else:\n",
    "        temp = shapley_value_sampling.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "        attributions_svs = torch.cat((attributions_svs, temp), dim = 0)\n",
    "\n",
    "torch.save(attributions_svs, \"ImageNet/attributions_svs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above took 6 minute 41.8 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need feature mask\n",
    "feature_ablation = FeatureAblation(model_cuda)\n",
    "attributions_fa = None\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "    if attributions_fa is None:\n",
    "        attributions_fa = feature_ablation.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "    else:\n",
    "        temp = feature_ablation.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "        attributions_fa = torch.cat((attributions_fa, temp), dim = 0)\n",
    "\n",
    "torch.save(attributions_fa, \"ImageNet/attributions_fa.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above took 14.8 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need feature mask\n",
    "kernel_shap = KernelShap(model_cuda)\n",
    "attributions_ks = None\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_slice = slice(i * len(proper_data) // num_batches, (i + 1) * len(proper_data) // num_batches)\n",
    "    if attributions_ks is None:\n",
    "        attributions_ks = kernel_shap.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "    else:\n",
    "        temp = kernel_shap.attribute(proper_data[batch_slice], target=preds[batch_slice], feature_mask=proper_masks[batch_slice])\n",
    "        attributions_ks = torch.cat((attributions_ks, temp), dim = 0)\n",
    "\n",
    "torch.save(attributions_ks, \"ImageNet/attributions_ks.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above took 31.0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "noise_tunnel = NoiseTunnel(integrated_gradients) # base on EnsembleXAI\n",
    "attributions_nt = get_attributions(noise_tunnel, num_batches = 500)\n",
    "torch.save(attributions_nt, \"ImageNet/attributions_nt.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsembleXAI.Normalization import mean_var_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = {\n",
    "    'attributions_ig': torch.load('ImageNet/attributions_ig.pt'),\n",
    "    'attributions_s': torch.load('ImageNet/attributions_s.pt'),\n",
    "    'attributions_gs': torch.load('ImageNet/attributions_gs.pt'),\n",
    "    'attributions_gb': torch.load('ImageNet/attributions_gb.pt'),\n",
    "    'attributions_d': torch.load('ImageNet/attributions_d.pt'),\n",
    "    'attributions_ixg': torch.load('ImageNet/attributions_ixg.pt'),\n",
    "    'attributions_l': torch.load('ImageNet/attributions_l.pt'),\n",
    "    'attributions_o': torch.load('ImageNet/attributions_o.pt'),\n",
    "    'attributions_svs': torch.load('ImageNet/attributions_svs.pt'),\n",
    "    'attributions_fa': torch.load('ImageNet/attributions_fa.pt'),\n",
    "    'attributions_ks': torch.load('ImageNet/attributions_ks.pt'),\n",
    "    'attributions_nt': torch.load('ImageNet/attributions_nt.pt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_attributions = {attr: mean_var_normalize(attributions[attr]) for attr in attributions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EnsembleXAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsembleXAI.Ensemble import normEnsembleXAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = torch.stack([normalized_attributions[attr] for attr in normalized_attributions], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = normEnsembleXAI(explanations.detach(), aggregating_func='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agg, \"ImageNet/agg.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs471_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
